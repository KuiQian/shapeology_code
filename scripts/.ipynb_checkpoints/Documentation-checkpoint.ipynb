{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mController.py\u001b[m\u001b[m\r\n",
      "Create sequence of VQs.py\r\n",
      "Documentation.ipynb\r\n",
      "MasterProcessor.py\r\n",
      "diffusion_maps.py\r\n",
      "\u001b[31mextractPatches.py\u001b[m\u001b[m\r\n",
      "files\r\n",
      "\u001b[31mrun_job.py\u001b[m\u001b[m\r\n",
      "\u001b[31mtest.py\u001b[m\u001b[m\r\n",
      "\u001b[31mwatchdog.py\u001b[m\u001b[m\r\n",
      "\u001b[31mwatchdog.sh\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MasterProcessor.py\n",
    "defunct, replaced with \"Controller\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controller.py\n",
    "\n",
    "Top level controller of processing\n",
    "\n",
    "```\n",
    "usage: Controller.py [-h] scripts s3location local_data\n",
    "\n",
    "positional arguments:\n",
    "  scripts     path to the directory with the scripts\n",
    "  s3location  path to the s3 directory with the lossless images\n",
    "  local_data  path to the local data directory\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import psutil\n",
    "import socket\n",
    "from os import getpid,mkdir,system\n",
    "from subprocess import Popen,PIPE\n",
    "from os.path import isfile\n",
    "from glob import glob\n",
    "from time import sleep,time\n",
    "from os.path import isfile\n",
    "from sys import argv\n",
    "import re\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "def run(command):\n",
    "    print('cmd=',command)\n",
    "    system(command)\n",
    "    \n",
    "def runPipe(command):\n",
    "    print('runPipe cmd=',command)\n",
    "    p=Popen(command.split(),stdout=PIPE,stderr=PIPE)\n",
    "    L=p.communicate()\n",
    "    stdout=L[0].decode(\"utf-8\").split('\\n')\n",
    "    stderr=L[1].decode(\"utf-8\").split('\\n')\n",
    "    return stdout,stderr\n",
    "\n",
    "def clock(message):\n",
    "    print('%8.1f \\t%s'%(time(),message))\n",
    "    time_log.append((time(),message))\n",
    "\n",
    "def printClock():\n",
    "    t=time_log[0][0]\n",
    "    for i in range(1,len(time_log)):\n",
    "        print('%8.1f \\t%s'%(time_log[i][0]-t,time_log[i][1]))\n",
    "        t=time_log[i][0]\n",
    "\n",
    "def list_s3_files(stack_directory):\n",
    "    stdout,stderr=runPipe(\"aws s3 ls %s/ \"%(stack_directory))\n",
    "    return stdout\n",
    "    \n",
    "def get_file_table(stack_directory,pattern=r'(.*)\\.([^\\.]*)$'):\n",
    "    \"\"\"create a table of the files in a directory corresponding to a stack:\n",
    "    stack_directory: the location of the directory on s3.\n",
    "    example: s3://mousebraindata-open/MD657/\n",
    "    \"\"\"\n",
    "\n",
    "    stdout = list_s3_files(stack_directory)\n",
    "    pat=re.compile(pattern)\n",
    "\n",
    "    T={}\n",
    "    for file in stdout:\n",
    "        parts=file.strip().split()\n",
    "        if len(parts)!=4:\n",
    "            continue\n",
    "        filename=parts[3]\n",
    "        if not 'lossless.' in filename:\n",
    "            continue\n",
    "        m=pat.match(filename)\n",
    "        if m:\n",
    "            file,ext= m.groups()\n",
    "            info=(ext,parts[0]+' '+parts[1])\n",
    "            if file in T:\n",
    "                T[file].append(info)\n",
    "            else:\n",
    "                T[file]=[info]\n",
    "        else:\n",
    "            print(filname,'no match')\n",
    "    return T\n",
    "\n",
    "def find_and_lock(stack_directory):\n",
    "    \"\"\" find a section file without a lock and lock it\"\"\"\n",
    "    T=get_file_table(stack_directory)\n",
    "\n",
    "    while True:\n",
    "        #find a file without a lock\n",
    "        found=False\n",
    "        for item in T.items():\n",
    "            if len(item[1])==1:\n",
    "                found=True\n",
    "                break\n",
    "        if not found:\n",
    "            return None\n",
    "        \n",
    "        filename=item[0]\n",
    "        extensions=item[1]\n",
    "\n",
    "        #create a lock\n",
    "        hostname=socket.gethostname().replace('.','+')\n",
    "        flagname=filename+'.lock-'+hostname\n",
    "        open(scripts+'/'+flagname,'w').write(flagname+'\\n')\n",
    "\n",
    "        command='aws s3 cp %s %s/%s'%(scripts+'/'+flagname,stack_directory,flagname)\n",
    "        run(command)\n",
    "\n",
    "        # check to make sure that there is only one lock.\n",
    "        T=get_file_table(stack_directory)\n",
    "        extensions=T[filename]\n",
    "        if len(extensions)==2:\n",
    "            return filename\n",
    "    \n",
    "        # translation of date for better handling of two machines putting locks \n",
    "        # at nearly the same time\n",
    "        # comparing the time stamps of the locks can be used to resolve who was firstand should continue\n",
    "        # and who should look for another file.\n",
    "        # from datetime import datetime\n",
    "        # d1=datetime.strptime('2018-08-28 21:16:34','%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def process_tiles(tile_pattern):\n",
    "    i=0\n",
    "    print('tile_pattern=',tile_pattern)\n",
    "    for infile in glob(tile_pattern):\n",
    "        stem=infile[:-4]\n",
    "        #print ('infile=%s, stem=%s'%(infile,stem))\n",
    "        lockfile=stem+'.lock'\n",
    "        if not isfile(lockfile):\n",
    "            i+=1\n",
    "            print('got lock',lockfile,i)\n",
    "            run('python3 {0}/run_job.py {0} {1}'.format(scripts,stem))\n",
    "            sleep(0.1)\n",
    "        else:\n",
    "            #print('\\r %s exists'%lockfile,end='')\n",
    "            continue\n",
    "\n",
    "        # Wait if load is too high\n",
    "        load=np.mean(psutil.cpu_percent(percpu=True))\n",
    "        print(' %5d                            load: %6.2f'%(i,load))\n",
    "        j=0\n",
    "        while load>85:\n",
    "            print(' %5d    Sleep:%3d               load: %6.2f'%(i,j,load))\n",
    "            j+=1\n",
    "            sleep(2)\n",
    "            load=np.mean(psutil.cpu_percent(percpu=True))\n",
    "\n",
    "        print('\\nload low enough',load)\n",
    "    return i\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"scripts\", type=str,\n",
    "                        help=\"path to the directory with the scripts\")\n",
    "    parser.add_argument(\"s3location\", type=str,\n",
    "                        help=\"path to the s3 directory with the lossless images\")\n",
    "    parser.add_argument(\"local_data\",type=str,\n",
    "                        help=\"path to the local data directory\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    scripts=args.scripts\n",
    "    stack_directory=args.s3location\n",
    "    local_data=args.local_data\n",
    "    \n",
    "    time_log=[]\n",
    "\n",
    "    clock('starting Controller with stack_directory=%s, local_data=%s'%(stack_directory,local_data))\n",
    "\n",
    "    try:\n",
    "        #preparations: make dirs data and data/tiles\n",
    "        run('sudo chmod 0777 /dev/shm/')\n",
    "        mkdir(local_data)\n",
    "        mkdir(local_data+'/tiles')\n",
    "        clock('created data directory')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    while True:\n",
    "        #find an unprocessed file on S3\n",
    "        stem=find_and_lock(stack_directory)\n",
    "        clock('found and locked %s'%stem)\n",
    "\n",
    "        if stem==None:\n",
    "            print('all files processed')\n",
    "            break\n",
    "\n",
    "        run('rm -rf %s/*'%(local_data))\n",
    "        run('mkdir %s/tiles'%local_data)\n",
    "        clock('cleaning local directory')\n",
    "\n",
    "\n",
    "        #Bring in a file and break it into tiles\n",
    "        run('aws s3 cp %s/%s.jp2 %s/%s.jp2'%(stack_directory,stem,local_data,stem))\n",
    "        clock('copied from s3: %s'%stem)\n",
    "        run('kdu_expand -i %s/%s.jp2 -o %s/%s.tif'%(local_data,stem,local_data,stem))\n",
    "        clock('translated into tif')\n",
    "        run('convert %s/%s.tif -crop 1000x1000  +repage  +adjoin  %s'%\n",
    "            (local_data,stem,local_data)+'/tiles/tiles_%02d.tif')\n",
    "        clock('broke into tiles')\n",
    "\n",
    "        # perform analysis\n",
    "        i=process_tiles('%s/tiles/tiles_*.tif'%local_data)\n",
    "        clock('1 - processed %6d tiles'%i)\n",
    "        i=process_tiles('%s/tiles/tiles_*.tif'%local_data)\n",
    "        clock('2 - processed %6d tiles'%i)\n",
    "\n",
    "        #copy results to s3\n",
    "        run(\"tar czf {0}/{1}_patches.tgz {0}/tiles/*.pkl {0}/tiles/*.log {0}/tiles/*.lock\".format(local_data,stem))\n",
    "        clock('created tar file {0}/{1}_patches.tgz'.format(local_data,stem))\n",
    "\n",
    "        run('aws s3 cp {0}/{1}_patches.tgz {2}/'.format(local_data,stem,stack_directory))\n",
    "        clock('copy tar file to S3')\n",
    "\n",
    "    printClock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_job.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchdog.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchdog.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractPatches.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Create sequence of VQs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_maps.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
