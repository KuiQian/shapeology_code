{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import skimage\n",
    "#%matplotlib inline\n",
    "%pylab inline\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "from glob import glob\n",
    "sys.path.append(os.environ['REPO_DIR'])\n",
    "from extractPatches import patch_extractor\n",
    "from lib.utils import configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = 'MD594'\n",
    "fp = os.path.join(os.environ['ROOT_DIR'], 'CSHL_data_processed', stack, stack + '_sorted_filenames.txt')\n",
    "with open(fp, 'r') as f:\n",
    "    fn_idx_tuples = [line.strip().split() for line in f.readlines()]\n",
    "    section_to_filename = {int(idx): fn for fn, idx in fn_idx_tuples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(os.environ['ROOT_DIR'], 'CSHL_data_processed', stack, 'All_patch_locations.pkl')\n",
    "all_patch_locations = pickle.load(open(fname, 'rb'), encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CDF(x):\n",
    "    x=np.sort(x)\n",
    "    size=x.shape[0]\n",
    "    y=np.arange(0,size)/size\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(patch,params):\n",
    "    extractor=patch_extractor(patch,params)\n",
    "    tile=patch #cv2.imread(patch,0)\n",
    "    if params['preprocessing']['polarity']==-1:\n",
    "        tile = 255-tile\n",
    "    min_std=params['preprocessing']['min_std']\n",
    "    _std = np.std(tile.flatten())\n",
    "\n",
    "    extracted = []\n",
    "    if _std < min_std:\n",
    "        print('image',patches[i],'std=',_std, 'too blank')\n",
    "        features.append([0] * 201)\n",
    "    else:\n",
    "        Stats = extractor.segment_cells(tile)\n",
    "        cells = extractor.extract_blobs(Stats,tile)\n",
    "        cells = pd.DataFrame(cells)\n",
    "        cells = cells[cells['padded_patch'].notnull()]\n",
    "        cells = cells.drop(['padded_patch','left','top'],1)\n",
    "        cells = np.asarray(cells)\n",
    "        for k in range(len(cells)):\n",
    "            cells[k][0] = cells[k][0][:10]\n",
    "        origin = np.concatenate((np.array(list(cells[:,0])),cells[:,1:]),axis=1)\n",
    "        for k in range(origin.shape[1]):\n",
    "            x, y = CDF(origin[:,k])\n",
    "            ten = [x[np.argmin(np.absolute(y-0.1*(j+1)))] for j in range(10)]\n",
    "            extracted.extend(ten)\n",
    "        extracted.extend([cells.shape[0]/100])\n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "param = {}\n",
    "param['max_depth']= 3   # depth of tree\n",
    "param['eta'] = 0.2      # shrinkage parameter\n",
    "param['silent'] = 1     # not silent\n",
    "param['objective'] = 'binary:logistic' #'multi:softmax'\n",
    "param['nthread'] = 7 # Number of threads used\n",
    "param['num_class']=1\n",
    "num_round = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'aws', 'paths': {'scripts_dir': '/data/Github/shapeology_code/scripts', 'exec_dir': '/home/ubuntu/Datajoint_Interface/project_schemas/atlas_schema_python_v3/Cell_Extractor/', 'data_dir': '/data/BstemAtlasDataBackup/ucsd_brain/', 'DiffusionMap': '/data/Github/shapeology_code/notebooks/diffusionMap'}, 'preprocessing': {'polarity': -1, 'min_std': 10, 'offset': -20, 'min_area': 10}, 'normalization': {'size_thresholds': [15, 51, 201]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/Github/shapeology_code/scripts/lib/utils.py:22: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  self.D=yaml.load(open(yamlFile,'r'))\n"
     ]
    }
   ],
   "source": [
    "yamlfile=os.environ['REPO_DIR']+'/shape_params-aws.yaml'\n",
    "params=configuration(yamlfile).getParams()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_structures = ['5N', '6N', '7n', 'Amb', 'LC', 'LRt', 'Pn', 'Tz', 'VLL', 'RMC', \\\n",
    "                     'SNC', 'SNR', '3N', '4N', 'Sp5I', 'Sp5O', 'Sp5C', 'PBG', '10N', 'VCA', 'VCP', 'DC']\n",
    "singular_structures = ['AP', '12N', 'RtTg', 'SC', 'IC']\n",
    "\n",
    "all_structures = paired_structures + singular_structures\n",
    "stack = 'MD594'\n",
    "cell_dir = os.environ['ROOT_DIR'] + 'CSHL_patches_features_less/MD589/'\n",
    "raw_images_root = os.environ['ROOT_DIR']+'/CSHL_data_processed/'+stack+'/'+stack+'_prep2_lossless_gray/'\n",
    "savepath = os.environ['ROOT_DIR']+'/CSHL_hsv/'\n",
    "if not os.path.exists(savepath):\n",
    "    os.mkdir(savepath)\n",
    "savepath = savepath+stack+'/'\n",
    "if not os.path.exists(savepath):\n",
    "    os.mkdir(savepath)\n",
    "\n",
    "resol = 0.46\n",
    "half_size = 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amb finished in 183.3 seconds\n",
      "LC finished in 197.7 seconds\n",
      "LRt finished in 189.0 seconds\n",
      "Pn finished in 201.6 seconds\n",
      "Tz finished in 180.0 seconds\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "for structure in all_structures:  \n",
    "    t1=time()\n",
    "    subpath = savepath+structure+'/'\n",
    "    if not os.path.exists(subpath):\n",
    "        os.mkdir(subpath)\n",
    "    else:\n",
    "        continue\n",
    "    fp =[dir for dir in glob(cell_dir+structure+'/*')]\n",
    "    features = []\n",
    "    labels = []\n",
    "    for state in range(2):\n",
    "        clouds = pickle.load(open(fp[state],'rb'))\n",
    "        features.extend(np.array(clouds))\n",
    "        labels.extend([1-state]*len(clouds))\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(features, labels, test_size=0.30, random_state=6)\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    bst = xgb.train(param, dtrain, num_round, verbose_eval=False)\n",
    "\n",
    "\n",
    "    section_indices = [index for index in all_patch_locations[structure].keys()]\n",
    "    section_indices = np.sort(section_indices)\n",
    "    if len(section_indices)>10:\n",
    "        half = int(len(section_indices)/2)\n",
    "        section_indices = section_indices[half-5:half+5]\n",
    "    \n",
    "    negative = structure+'_surround_500um_noclass'\n",
    "    structures = [structure, negative]\n",
    "\n",
    "    for section in section_indices:\n",
    "        img = cv2.imread( raw_images_root+section_to_filename[section]+'_prep2_lossless_gray.tif', 2)\n",
    "        m, n = img.shape\n",
    "        [left, right, up, down] = [int(max(min(all_patch_locations[negative][section][:,0])-half_size,0)), \n",
    "                                   int(min(np.ceil(max(all_patch_locations[negative][section][:,0])+half_size),n-1)),\n",
    "                                   int(max(min(all_patch_locations[negative][section][:,1])-half_size,0)), \n",
    "                                   int(min(np.ceil(max(all_patch_locations[negative][section][:,1])+half_size),m-1))]\n",
    "\n",
    "        hsv = np.zeros([down-up+1, right-left+1,3])\n",
    "        hsv[:,:,2] = 1\n",
    "        for state in range(2):\n",
    "            structure = structures[state]\n",
    "            n_choose = min(len(all_patch_locations[structure][section]),20)\n",
    "            indices_choose = np.random.choice(range(len(all_patch_locations[structure][section])),n_choose,replace=False)\n",
    "            patches_choose = all_patch_locations[structure][section][indices_choose,:]\n",
    "            for index in range(n_choose):\n",
    "                try:\n",
    "                    x = int( float( patches_choose[index][0] ) )\n",
    "                    y = int( float( patches_choose[index][1] ) )\n",
    "                    patch = img[y-half_size:y+half_size,x-half_size:x+half_size]\n",
    "                    extracted = features_extractor(patch, params)\n",
    "                    xtest=xgb.DMatrix(extracted)\n",
    "                    score = bst.predict(xtest, output_margin=True, ntree_limit=bst.best_ntree_limit)\n",
    "                    value_img = patch/255\n",
    "                    hsv[y-half_size-up:y+half_size-up, x-half_size-left:x+half_size-left,2] = value_img\n",
    "                    satua_img = np.zeros_like(value_img)+score\n",
    "                    origin = hsv[y-half_size-up:y+half_size-up, x-half_size-left:x+half_size-left,1]\n",
    "                    comp = np.absolute(origin)-np.absolute(satua_img)\n",
    "                    hsv[y-half_size-up:y+half_size-up, x-half_size-left:x+half_size-left,1] = origin*(comp>0)+satua_img*(comp<0)\n",
    "                except:\n",
    "                    continue\n",
    "        hsv[:,:,0] = (hsv[:,:,1]>0)*0.66 + (hsv[:,:,1]<0)*1.0\n",
    "        hsv[:,:,1] = np.absolute(hsv[:,:,1])\n",
    "        hsv[:,:,1] = hsv[:,:,1]/hsv[:,:,1].max()\n",
    "        rgb = skimage.color.hsv2rgb(hsv)\n",
    "        rgb=rgb*255\n",
    "        rgb=rgb.astype(np.uint8)\n",
    "        filename = subpath + structures[0]+'_'+str(section)+'.tif'\n",
    "        cv2.imwrite(filename, rgb)\n",
    "    print(structures[0] + ' finished in %5.1f seconds' % (time() - t1))\n",
    "print('Finished in %5.1f seconds' % (time() - t0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shapeology",
   "language": "python",
   "name": "shapeology"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
