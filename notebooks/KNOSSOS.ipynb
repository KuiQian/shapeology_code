{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage\n",
    "import os\n",
    "import sys\n",
    "import sqlite3\n",
    "import shutil\n",
    "from time import time\n",
    "sys.path.append(os.environ['REPO_DIR'])\n",
    "from lib.utils import configuration, run\n",
    "from matplotlib.path import Path\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CDF(x):\n",
    "    x=np.sort(x)\n",
    "    size=x.shape[0]\n",
    "    y=np.arange(0,size)/size\n",
    "    return x,y\n",
    "\n",
    "\n",
    "def setup_download_from_s3(rel_fp, recursive=True):\n",
    "    s3_fp = 's3://mousebrainatlas-data/' + rel_fp\n",
    "    local_fp = os.environ['ROOT_DIR'] + rel_fp\n",
    "\n",
    "    if os.path.exists(local_fp):\n",
    "        print('ALREADY DOWNLOADED FILE')\n",
    "        return\n",
    "\n",
    "    if recursive:\n",
    "        run('aws s3 cp --recursive {0} {1}'.format(s3_fp, local_fp))\n",
    "    else:\n",
    "        run('aws s3 cp {0} {1}'.format(s3_fp, local_fp))\n",
    "\n",
    "def setup_upload_from_s3(rel_fp, recursive=True):\n",
    "    s3_fp = 's3://mousebrainatlas-data/' + rel_fp\n",
    "    local_fp = os.environ['ROOT_DIR'] + rel_fp\n",
    "\n",
    "    if recursive:\n",
    "        run('aws s3 cp --recursive {0} {1}'.format(local_fp, s3_fp))\n",
    "    else:\n",
    "        run('aws s3 cp {0} {1}'.format(local_fp, s3_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALREADY DOWNLOADED FILE\n",
      "ALREADY DOWNLOADED FILE\n",
      "ALREADY DOWNLOADED FILE\n"
     ]
    }
   ],
   "source": [
    "stack = 'MD594'\n",
    "fp = os.path.join('CSHL_data_processed', stack, stack + '_sorted_filenames.txt')\n",
    "setup_download_from_s3(fp, recursive=False)\n",
    "with open(os.environ['ROOT_DIR']+fp, 'r') as f:\n",
    "    fn_idx_tuples = [line.strip().split() for line in f.readlines()]\n",
    "    section_to_filename = {int(idx): fn for fn, idx in fn_idx_tuples}\n",
    "\n",
    "\n",
    "fname = os.path.join('CSHL_data_processed', stack, 'Annotation.npy')\n",
    "setup_download_from_s3(fname, recursive=False)\n",
    "annotation = np.load(os.environ['ROOT_DIR']+fname, allow_pickle = True, encoding='latin1')\n",
    "contours = pd.DataFrame(annotation)\n",
    "contours = contours.rename(columns={0:\"name\", 1:\"section\", 2:\"vertices\"})\n",
    "contours_grouped = contours.groupby('section')\n",
    "valid_sections = np.sort(contours['section'].unique())\n",
    "\n",
    "fn = 'CSHL_data_processed/MD589/ThresholdsV2.pkl'\n",
    "setup_download_from_s3(fn, recursive=False)\n",
    "thresholds = pickle.load(open(os.environ['ROOT_DIR']+fn,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = 'CSHL_cells_mark/'\n",
    "if not os.path.exists(os.environ['ROOT_DIR']+savepath):\n",
    "    os.mkdir(os.environ['ROOT_DIR']+savepath)\n",
    "savepath = savepath+stack+'/'\n",
    "if not os.path.exists(os.environ['ROOT_DIR']+savepath):\n",
    "    os.mkdir(os.environ['ROOT_DIR']+savepath)\n",
    "savepath = savepath+'color/'\n",
    "if not os.path.exists(os.environ['ROOT_DIR']+savepath):\n",
    "    os.mkdir(os.environ['ROOT_DIR']+savepath)\n",
    "\n",
    "resol = 0.46\n",
    "\n",
    "paired_structures = ['5N', '6N', '7N', '7n', 'Amb', 'LC', 'LRt', 'Pn', 'Tz', 'VLL', 'RMC', \\\n",
    "                     'SNC', 'SNR', '3N', '4N', 'Sp5I', 'Sp5O', 'Sp5C', 'PBG', '10N', 'VCA', 'VCP', 'DC']\n",
    "singular_structures = ['AP', '12N', 'RtTg', 'SC', 'IC']\n",
    "\n",
    "all_structures = paired_structures + singular_structures\n",
    "\n",
    "margin = 500/0.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 26s, sys: 3min 21s, total: 17min 47s\n",
      "Wall time: 20min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_images_root = 'CSHL_data_processed/'+stack+'/'+stack+'_prep2_lossless_gray/'\n",
    "for section in valid_sections:\n",
    "    img_fn = raw_images_root + section_to_filename[section] + '_prep2_lossless_gray.tif'\n",
    "#     setup_download_from_s3(img_fn, recursive=False)\n",
    "    img = cv2.imread(os.environ['ROOT_DIR']+img_fn, 2)\n",
    "#     whole = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "#     polygons = [(contour['name'], contour['vertices']) \\\n",
    "#             for contour_id, contour in contours_grouped.get_group(section).iterrows()]\n",
    "#     count = 0    \n",
    "#     cs = []\n",
    "#     for contour_id, contour in polygons:\n",
    "#         structure = contour_id\n",
    "#         if structure not in all_structures:\n",
    "#             continue\n",
    "#         polygon = contour.copy()\n",
    "#         cs.append(polygon.astype(np.int32))\n",
    "#         count += 1\n",
    "#         print(section, structure, count, '/', len(polygons))\n",
    "#     com = cv2.polylines(whole.copy(), cs, True, [255, 0, 0], 3, lineType=50)\n",
    "    filename = savepath + str(section) + '.tif'\n",
    "#     com = cv2.cvtColor(com, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(os.environ['ROOT_DIR']+filename, img)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kuiqian/Github/venv/shapeology_venv/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "ALREADY DOWNLOADED FILE\n",
      "ALREADY DOWNLOADED FILE\n",
      "ALREADY DOWNLOADED FILE\n",
      "ALREADY DOWNLOADED FILE\n",
      "ALREADY DOWNLOADED FILE\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_cells_mark/MD594/VCA/110_VCA_mark.png s3://mousebrainatlas-data/CSHL_cells_mark/MD594/VCA/110_VCA_mark.png\n",
      "upload: ../../../BstemAtlasDataBackup/ucsd_brain/CSHL_cells_mark/MD594/VCA/110_VCA_mark.png to s3://mousebrainatlas-data/CSHL_cells_mark/MD594/VCA/110_VCA_mark.png\n",
      "110 VCA 1 / 3\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_cells_mark/MD594/VCP/110_VCP_mark.png s3://mousebrainatlas-data/CSHL_cells_mark/MD594/VCP/110_VCP_mark.png\n",
      "upload: ../../../BstemAtlasDataBackup/ucsd_brain/CSHL_cells_mark/MD594/VCP/110_VCP_mark.png to s3://mousebrainatlas-data/CSHL_cells_mark/MD594/VCP/110_VCP_mark.png\n",
      "110 VCP 2 / 3\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_cells_mark/MD594/DC/110_DC_mark.png s3://mousebrainatlas-data/CSHL_cells_mark/MD594/DC/110_DC_mark.png\n",
      "upload: ../../../BstemAtlasDataBackup/ucsd_brain/CSHL_cells_mark/MD594/DC/110_DC_mark.png to s3://mousebrainatlas-data/CSHL_cells_mark/MD594/DC/110_DC_mark.png\n",
      "110 DC 3 / 3\n"
     ]
    }
   ],
   "source": [
    "script_dir = os.environ['REPO_DIR']\n",
    "! python $script_dir/Cell_mark.py 'MD594' 110 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run cmd= aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_cells_mark/MD594/ /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_cells_mark/MD594/\n"
     ]
    }
   ],
   "source": [
    "setup_download_from_s3('CSHL_cells_mark/MD594/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shapeology",
   "language": "python",
   "name": "shapeology_code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
